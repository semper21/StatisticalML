{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 5000: loss 0.100000\n",
      "iteration 100 / 5000: loss 0.028190\n",
      "iteration 200 / 5000: loss 0.017769\n",
      "iteration 300 / 5000: loss 0.014181\n",
      "iteration 400 / 5000: loss 0.012271\n",
      "iteration 500 / 5000: loss 0.011083\n",
      "iteration 600 / 5000: loss 0.010240\n",
      "iteration 700 / 5000: loss 0.009578\n",
      "iteration 800 / 5000: loss 0.009056\n",
      "iteration 900 / 5000: loss 0.008641\n",
      "iteration 1000 / 5000: loss 0.008296\n",
      "iteration 1100 / 5000: loss 0.007994\n",
      "iteration 1200 / 5000: loss 0.007751\n",
      "iteration 1300 / 5000: loss 0.007537\n",
      "iteration 1400 / 5000: loss 0.007343\n",
      "iteration 1500 / 5000: loss 0.007172\n",
      "iteration 1600 / 5000: loss 0.007016\n",
      "iteration 1700 / 5000: loss 0.006875\n",
      "iteration 1800 / 5000: loss 0.006746\n",
      "iteration 1900 / 5000: loss 0.006625\n",
      "iteration 2000 / 5000: loss 0.006511\n",
      "iteration 2100 / 5000: loss 0.006402\n",
      "iteration 2200 / 5000: loss 0.006300\n",
      "iteration 2300 / 5000: loss 0.006200\n",
      "iteration 2400 / 5000: loss 0.006104\n",
      "iteration 2500 / 5000: loss 0.006011\n",
      "iteration 2600 / 5000: loss 0.005923\n",
      "iteration 2700 / 5000: loss 0.005839\n",
      "iteration 2800 / 5000: loss 0.005759\n",
      "iteration 2900 / 5000: loss 0.005682\n",
      "iteration 3000 / 5000: loss 0.005608\n",
      "iteration 3100 / 5000: loss 0.005536\n",
      "iteration 3200 / 5000: loss 0.005469\n",
      "iteration 3300 / 5000: loss 0.005405\n",
      "iteration 3400 / 5000: loss 0.005344\n",
      "iteration 3500 / 5000: loss 0.005288\n",
      "iteration 3600 / 5000: loss 0.005231\n",
      "iteration 3700 / 5000: loss 0.005177\n",
      "iteration 3800 / 5000: loss 0.005123\n",
      "iteration 3900 / 5000: loss 0.005071\n",
      "iteration 4000 / 5000: loss 0.005022\n",
      "iteration 4100 / 5000: loss 0.004977\n",
      "iteration 4200 / 5000: loss 0.004930\n",
      "iteration 4300 / 5000: loss 0.004887\n",
      "iteration 4400 / 5000: loss 0.004846\n",
      "iteration 4500 / 5000: loss 0.004805\n",
      "iteration 4600 / 5000: loss 0.004766\n",
      "iteration 4700 / 5000: loss 0.004729\n",
      "iteration 4800 / 5000: loss 0.004692\n",
      "iteration 4900 / 5000: loss 0.004656\n",
      "Accuracy of model on training data is:  0.98825\n",
      "Accuracy of model on test data is:  0.988\n",
      "Top 15 predictors of spam are: \n",
      "click\n",
      "remov\n",
      "our\n",
      "pleas\n",
      "basenumb\n",
      "here\n",
      "guarante\n",
      "your\n",
      "you\n",
      "free\n",
      "nbsp\n",
      "will\n",
      "hour\n",
      "visit\n",
      "market\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing, metrics\n",
    "import utils\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from linear_classifier import LinearSVM_twoclass\n",
    "\n",
    "# load the SPAM email training dataset\n",
    "\n",
    "X,y = utils.load_mat('data/spamTrain.mat')\n",
    "yy = np.ones(y.shape)\n",
    "yy[y==0] = -1\n",
    "\n",
    "# load the SPAM email test dataset\n",
    "\n",
    "test_data = scipy.io.loadmat('data/spamTest.mat')\n",
    "X_test = test_data['Xtest']\n",
    "y_test = test_data['ytest'].flatten()\n",
    "\n",
    "##################################################################################\n",
    "#  YOUR CODE HERE for training the best performing SVM for the data above.       #\n",
    "#  what should C be? What should num_iters be? Should X be scaled?               #\n",
    "#  should X be kernelized? What should the learning rate be? What should the     #\n",
    "#  number of iterations be?                                                      #\n",
    "##################################################################################\n",
    "'''\n",
    "from sklearn import cross_validation\n",
    "XX, XXval, yyy, yyval = cross_validation.train_test_split(X, yy, test_size=0.2)\n",
    "\n",
    "Cvals = [0.1, 0.3, 1, 3, 10, 30]\n",
    "lr_vals = [1e-2, 3e-2, 1e-1, 3e-1, 1, 3]\n",
    "iter_vals = [1000, 5000, 10000, 25000]\n",
    "\n",
    "best_acc = 0\n",
    "scaler = preprocessing.StandardScaler().fit(XX)\n",
    "scaleX = scaler.transform(XX)\n",
    "XX = np.vstack([np.ones((scaleX.shape[0],)), scaleX.T]).T\n",
    "\n",
    "scalerval = preprocessing.StandardScaler().fit(XXval)\n",
    "scaleXval = scalerval.transform(XXval)\n",
    "XXval = np.vstack([np.ones((scaleXval.shape[0],)), scaleXval.T]).T\n",
    "\n",
    "for C in Cvals:\n",
    "    for lr in lr_vals:\n",
    "        for it in iter_vals:\n",
    "            svm = LinearSVM_twoclass()\n",
    "            svm.theta = np.zeros((XX.shape[1],))\n",
    "            svm.train(XX, yyy, learning_rate=lr, reg=C, num_iters=it, verbose=True)\n",
    "            yval_predict = svm.predict(XXval)\n",
    "            acc = metrics.accuracy_score(yyval, yval_predict)\n",
    "            print (\"C {}\".format(C), \"learning rate {}\".format(lr), \"iteration {}\".format(it), \"accuracy {}\".format(acc))\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_C = C\n",
    "                best_lr = lr\n",
    "                best_it = it\n",
    "print ('best', best_C, best_acc, best_lr, best_it)\n",
    "'''\n",
    "svm = LinearSVM_twoclass()\n",
    "svm.theta = np.zeros((X.shape[1],))\n",
    "\n",
    "best_C = 0.1\n",
    "best_lr = 0.03\n",
    "best_it = 5000\n",
    "\n",
    "svm.train(X, yy, learning_rate=1e-1, reg=best_C, num_iters=best_it, verbose=True)\n",
    "##################################################################################\n",
    "# YOUR CODE HERE for testing your best model's perfor                            #\n",
    "# what is the accuracy of your best model on the test set? On the training set?  #\n",
    "##################################################################################\n",
    "\n",
    "y_pred = svm.predict(X)\n",
    "print \"Accuracy of model on training data is: \", metrics.accuracy_score(yy,y_pred)\n",
    "\n",
    "yy_test = np.ones(y_test.shape)\n",
    "yy_test[y_test==0] = -1\n",
    "test_pred = svm.predict(X_test)\n",
    "print \"Accuracy of model on test data is: \", metrics.accuracy_score(yy_test,test_pred)\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "# ANALYSIS OF MODEL: Print the top 15 words that are predictive of spam and for  #\n",
    "# ham. Hint: use the coefficient values of the learned model                     #\n",
    "##################################################################################\n",
    "words, inv_words = utils.get_vocab_dict()\n",
    "\n",
    "index = np.argsort(svm.theta)[-15:]\n",
    "print \"Top 15 predictors of spam are: \"\n",
    "for i in range(-1,-16,-1):\n",
    "    print words[index[i]+1]\n",
    "    \n",
    "##################################################################################\n",
    "#                    END OF YOUR CODE                                            #\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 5000: loss 0.100000\n",
      "iteration 100 / 5000: loss 0.012546\n",
      "iteration 200 / 5000: loss 0.010541\n",
      "iteration 300 / 5000: loss 0.009462\n",
      "iteration 400 / 5000: loss 0.008759\n",
      "iteration 500 / 5000: loss 0.008242\n",
      "iteration 600 / 5000: loss 0.007825\n",
      "iteration 700 / 5000: loss 0.007477\n",
      "iteration 800 / 5000: loss 0.007185\n",
      "iteration 900 / 5000: loss 0.006938\n",
      "iteration 1000 / 5000: loss 0.006691\n",
      "iteration 1100 / 5000: loss 0.006455\n",
      "iteration 1200 / 5000: loss 0.006296\n",
      "iteration 1300 / 5000: loss 0.006192\n",
      "iteration 1400 / 5000: loss 0.005974\n",
      "iteration 1500 / 5000: loss 0.005839\n",
      "iteration 1600 / 5000: loss 0.005717\n",
      "iteration 1700 / 5000: loss 0.005823\n",
      "iteration 1800 / 5000: loss 0.005506\n",
      "iteration 1900 / 5000: loss 0.005445\n",
      "iteration 2000 / 5000: loss 0.005354\n",
      "iteration 2100 / 5000: loss 0.005218\n",
      "iteration 2200 / 5000: loss 0.005127\n",
      "iteration 2300 / 5000: loss 0.005115\n",
      "iteration 2400 / 5000: loss 0.005027\n",
      "iteration 2500 / 5000: loss 0.005123\n",
      "iteration 2600 / 5000: loss 0.004835\n",
      "iteration 2700 / 5000: loss 0.004780\n",
      "iteration 2800 / 5000: loss 0.004694\n",
      "iteration 2900 / 5000: loss 0.004682\n",
      "iteration 3000 / 5000: loss 0.004557\n",
      "iteration 3100 / 5000: loss 0.004794\n",
      "iteration 3200 / 5000: loss 0.004431\n",
      "iteration 3300 / 5000: loss 0.004390\n",
      "iteration 3400 / 5000: loss 0.004334\n",
      "iteration 3500 / 5000: loss 0.004454\n",
      "iteration 3600 / 5000: loss 0.004370\n",
      "iteration 3700 / 5000: loss 0.004165\n",
      "iteration 3800 / 5000: loss 0.004195\n",
      "iteration 3900 / 5000: loss 0.004100\n",
      "iteration 4000 / 5000: loss 0.004058\n",
      "iteration 4100 / 5000: loss 0.004003\n",
      "iteration 4200 / 5000: loss 0.004247\n",
      "iteration 4300 / 5000: loss 0.003908\n",
      "iteration 4400 / 5000: loss 0.004112\n",
      "iteration 4500 / 5000: loss 0.003889\n",
      "iteration 4600 / 5000: loss 0.003870\n",
      "iteration 4700 / 5000: loss 0.003711\n",
      "iteration 4800 / 5000: loss 0.003687\n",
      "iteration 4900 / 5000: loss 0.003657\n",
      "Accuracy of model on training data is:  0.98775\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1000,1000) and (4000,) not aligned: 1000 (dim 1) != 4000 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-678c616d32b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0myy_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0myy_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaleKtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Accuracy of model on test data is: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myy_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ywkim/Desktop/ML/COMP540/hw4/linear_classifier.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1000,1000) and (4000,) not aligned: 1000 (dim 1) != 4000 (dim 0)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#Cosine similarity kernels\n",
    "\n",
    "XK = cosine_similarity(X, Y=None, dense_output=True)\n",
    "scaler = preprocessing.StandardScaler().fit(XK)\n",
    "scaleK = scaler.transform(XK)\n",
    "KK = np.vstack([np.ones((scaleK.shape[0],)),scaleK]).T\n",
    "\n",
    "XKtest = cosine_similarity(X_test, Y=None, dense_output=True)\n",
    "scalertest = preprocessing.StandardScaler().fit(XKtest)\n",
    "scaleKtest = scalertest.transform(XKtest)\n",
    "KKtest = np.vstack([np.ones((scaleKtest.shape[0],)),scaleKtest]).T\n",
    "\n",
    "svm = LinearSVM_twoclass()\n",
    "svm.theta = np.zeros((XK.shape[1],))\n",
    "\n",
    "svm.train(scaleK, yy, learning_rate=best_lr, reg=best_C, num_iters=best_it, verbose=True)\n",
    "\n",
    "y_pred = svm.predict(scaleK)\n",
    "print \"Accuracy of model on training data is: \", metrics.accuracy_score(yy,y_pred)\n",
    "\n",
    "yy_test = np.ones(y_test.shape)\n",
    "yy_test[y_test==0] = -1\n",
    "test_pred = svm.predict(scaleKtest)\n",
    "print \"Accuracy of model on test data is: \", metrics.accuracy_score(yy_test,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Gaussian Kernels\n",
    "\n",
    "sigma = 0.02\n",
    "\n",
    "K = np.array([utils.gaussian_kernel(x1,x2,sigma) for x1 in X for x2 in X]).reshape(X.shape[0],X.shape[0])\n",
    "scaler = preprocessing.StandardScaler().fit(K)\n",
    "scaleK = scaler.transform(K)\n",
    "KK = np.vstack([np.ones((scaleK.shape[0],)),scaleK]).T\n",
    "yy = np.ones(y.shape)\n",
    "yy[y == 0] = -1\n",
    "svm = LinearSVM_twoclass()\n",
    "svm.theta = np.zeros((KK.shape[1],))\n",
    "C = 1\n",
    "svm.train(KK,yy,learning_rate=best_lr,reg=best_C,num_iters=best_it,verbose=True)\n",
    "y_pred = svm.predict(KK)\n",
    "print \"Accuracy on training data = \", metrics.accuracy_score(yy,y_pred)\n",
    "yy_test = np.ones(y_test.shape)\n",
    "yy_test[y_test==0] = -1\n",
    "test_pred = svm.predict(X_test)\n",
    "print \"Accuracy of model on test data is: \", metrics.accuracy_score(yy_test,test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
